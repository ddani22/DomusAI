# DomusAI - Sistema de Monitoreo y PredicciÃ³n de Consumo EnergÃ©tico

## Project Architecture & Data Flow

**Core Domain**: Energy consumption analysis and prediction for residential/community monitoring with automated reporting.

**Data Pipeline**: Raw CSV â†’ `limpiar_dataset.py` â†’ Clean CSV â†’ Analysis â†’ Predictions â†’ Reports â†’ Email notifications

**Key Data Schema**:
- **Input**: `Dataset de prueba de consumo.csv` with columns: `Date` (dd/mm/yy), `Time`, `Global_active_power`, `Global_reactive_power`, `Voltage`, `Global_intensity`, `Sub_metering_1-3`
- **Output**: `consumo_limpio_pruebas.csv` with `Datetime` index (converted to 4-digit years) and float64 columns

## Essential Patterns & Conventions

### Data Cleaning Workflow (`limpiar_dataset.py`)
```python
# Standard pattern for year conversion (2-digit to 4-digit)
def convertir_fecha_a_4_digitos(fecha_str):
    # Rule: 00-30 â†’ 2000-2030, 31-99 â†’ 1931-1999
    if aÃ±o_2d <= 30:
        aÃ±o_4d = 2000 + aÃ±o_2d
    elif aÃ±o_2d >= 70:
        aÃ±o_4d = 1900 + aÃ±o_2d
```

### Error Handling Philosophy
- Use `errors='coerce'` for datetime parsing to handle malformed data
- Fill `Sub_metering_3` nulls with 0 (domain-specific: sub-metering can be legitimately zero)
- Convert '?' and non-numeric values to NaN before float conversion

### Output Formatting
- Always use emoji-prefixed progress messages: `ğŸ”„`, `ğŸ“Š`, `âœ…`, `âš ï¸`
- Show data samples and statistics for verification
- Include comma-formatted numbers for readability: `f"{len(df):,}"`

## Project Structure

```
proyecto-energia/
â”‚â”€â”€ data/                    # Datasets originales y limpios
â”‚   â”œâ”€â”€ Dataset_original_test.csv
â”‚   â”œâ”€â”€ Dataset_clean_test.csv
â”‚
â”‚â”€â”€ notebooks/               # Jupyter Notebooks de pruebas y EDA
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_prediccion.ipynb
â”‚   â”œâ”€â”€ 03_anomalias.ipynb
â”‚
â”‚â”€â”€ src/                     # CÃ³digo principal en Python
â”‚   â”œâ”€â”€ data_cleaning.py     # Limpieza y preparaciÃ³n de datos
â”‚   â”œâ”€â”€ eda.py               # Funciones de anÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ prediction.py        # Modelos de predicciÃ³n
â”‚   â”œâ”€â”€ anomalies.py         # DetecciÃ³n de anomalÃ­as
â”‚   â”œâ”€â”€ reporting.py         # GeneraciÃ³n de reportes
â”‚   â”œâ”€â”€ email_sender.py      # EnvÃ­o de correos automÃ¡ticos
â”‚
â”‚â”€â”€ reports/                 # Reportes generados (PDF/HTML)
â”‚   â”œâ”€â”€ reporte_2025-01.pdf
â”‚
â”‚â”€â”€ README.md               # DescripciÃ³n del proyecto
â”‚â”€â”€ requirements.txt        # Dependencias de Python
```

## Technology Stack & Dependencies

**Core Processing**:
- **Python** - Backend de procesamiento de datos
- **Pandas/Numpy** - Limpieza y manipulaciÃ³n de datos

**Visualization**:
- **Matplotlib/Seaborn/Plotly** - VisualizaciÃ³n de datos

**Prediction Models**:
- **Statsmodels/Prophet/Scikit-learn/TensorFlow (LSTM)** - Modelos de predicciÃ³n de consumo

**Anomaly Detection**:
- **Scikit-learn/Isolation Forest/Autoencoders** - DetecciÃ³n de anomalÃ­as

**Data Storage**:
- **SQLite o InfluxDB** - Almacenamiento de datos

**Reporting & Communication**:
- **smtplib/yagmail** - EnvÃ­o de correos con reportes
- **Reportlab/WeasyPrint** - GeneraciÃ³n de reportes PDF/HTML

**Optional Dashboard**:
- **Flask/Dash** - Dashboard web para visualizaciÃ³n en tiempo real

**Current Dependencies**: Minimal setup (`pandas==2.3.2`, `numpy==2.3.3`) ready for expansion.

## Development Workflow

**Sequential Pipeline**:
1. **Limpieza de datos** â†’ preparar dataset (`data_cleaning.py`)
2. **EDA (anÃ¡lisis exploratorio)** â†’ grÃ¡ficas y patrones bÃ¡sicos (`eda.py`)
3. **Modelado predictivo** â†’ entrenar modelos de series temporales (`prediction.py`)
4. **DetecciÃ³n de anomalÃ­as** â†’ identificar consumos anormales (`anomalies.py`)
5. **GeneraciÃ³n de reportes** â†’ PDF/HTML con grÃ¡ficas y predicciones (`reporting.py`)
6. **EnvÃ­o automÃ¡tico de reportes** â†’ correo electrÃ³nico (`email_sender.py`)
7. **(Opcional) Dashboard web** â†’ monitoreo en tiempo real

**Current Status**:
- âœ… Dataset de prueba cargado
- âœ… Limpieza de datos (completada con `limpiar_dataset.py`)
- â³ **Next Priority**: ExploraciÃ³n inicial y visualizaciones
- ğŸ”„ **Upcoming**: Primer modelo de predicciÃ³n, detecciÃ³n de anomalÃ­as, reportes automÃ¡ticos## Energy Domain Knowledge

**Data Characteristics**:
- 1-minute resolution time series data (260,640 rows = ~6 months)
- Missing data patterns: ~3,771 nulls (1.4%) typically occur in clusters (sensor failures)
- Sub-metering values: 0-based, can legitimately be zero during off-peak hours
- Voltage range: ~230-245V (European standard)

**Expected Analysis Patterns**:
- Daily/weekly seasonality in consumption
- Peak hours: morning (7-9am) and evening (6-9pm)
- Anomalies: sudden spikes, prolonged high consumption, sensor failures

## Collaboration Context

**Team Structure**: Python/AI developer + Electronics partner (ESP32/Arduino, MQTT)
**Future Integration**: Real-time sensor data via MQTT â†’ Database â†’ Analysis pipeline